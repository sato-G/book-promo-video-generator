# ğŸ“‹ ä»Šå¾Œã®æ”¹å–„èª²é¡Œ

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€æ›¸ç±ãƒ—ãƒ­ãƒ¢ãƒ¼ã‚·ãƒ§ãƒ³å‹•ç”»ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ ã®ä»Šå¾Œã®æ”¹å–„æ¡ˆã‚’ã¾ã¨ã‚ãŸã‚‚ã®ã§ã™ã€‚

## ğŸ¨ 1. ç”»åƒå“è³ªã®å‘ä¸Š

### å•é¡Œç‚¹
- ç¾åœ¨DALL-E 3ã§ç”Ÿæˆã•ã‚Œã‚‹ç”»åƒãŒAIç”Ÿæˆã£ã½ãè¦‹ãˆã‚‹
- å®Ÿå†™é¢¨ã‚„ãƒªã‚¢ãƒ«ãªè³ªæ„ŸãŒä¸è¶³
- ã‚¹ã‚¿ã‚¤ãƒ«ã®ä¸€è²«æ€§ãŒä½ã„å ´åˆãŒã‚ã‚‹

### æ”¹å–„æ¡ˆ

#### 1.1 ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¼·åŒ–
```python
# ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®è¿½åŠ 
NEGATIVE_PROMPTS = [
    "AI-generated", "artificial", "fake", "unrealistic",
    "cartoonish", "low quality", "blurry", "distorted",
    "watermark", "text", "logo", "signature"
]

# ã‚¹ã‚¿ã‚¤ãƒ«åˆ¥è©³ç´°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
STYLE_ENHANCERS = {
    "Photorealistic": [
        "professional photography",
        "DSLR camera",
        "natural lighting",
        "8K resolution",
        "highly detailed",
        "realistic textures",
        "shallow depth of field"
    ],
    "Cinematic": [
        "film still",
        "movie scene",
        "dramatic lighting",
        "anamorphic lens",
        "color grading",
        "cinematic composition",
        "35mm film"
    ],
    "Anime": [
        "Studio Ghibli style",
        "hand-drawn animation",
        "cel shaded",
        "vibrant colors",
        "detailed background",
        "expressive characters"
    ]
}

# æ§‹å›³ã®æŒ‡å®šã‚’å¼·åŒ–
COMPOSITION_TEMPLATES = {
    "establishing": "wide shot, establishing scene, environmental details",
    "character": "medium shot, character focus, emotional expression",
    "action": "dynamic angle, motion blur, dramatic perspective",
    "detail": "close-up, macro photography, intricate details"
}
```

#### 1.2 DALL-E 3 HDå“è³ªã®ä½¿ç”¨
```python
# backend/image_generator_v2.py
response = client.images.generate(
    model="dall-e-3",
    prompt=full_prompt,
    size=size,
    quality="hd",  # "standard" ã‹ã‚‰ "hd" ã«å¤‰æ›´
    n=1
)
```
- **ãƒ¡ãƒªãƒƒãƒˆ**: ã‚ˆã‚Šé«˜å“è³ªã€è©³ç´°ãªç”»åƒ
- **ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**: ã‚³ã‚¹ãƒˆãŒç´„2å€ï¼ˆstandard: $0.040/ç”»åƒ â†’ hd: $0.080/ç”»åƒï¼‰

#### 1.3 ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ä¸€è²«æ€§ã®ç¢ºä¿
```python
# æœ€åˆã®ã‚·ãƒ¼ãƒ³ã§ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼ã®è©³ç´°ãªèª¬æ˜ã‚’ç”Ÿæˆ
# ä»¥é™ã®ã‚·ãƒ¼ãƒ³ã§åŒã˜èª¬æ˜ã‚’ä½¿ç”¨
character_description = "a young woman with long brown hair, wearing a blue dress, friendly smile"

# å„ã‚·ãƒ¼ãƒ³ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã«è¿½åŠ 
scene_prompt = f"{scene_description}, featuring {character_description}"
```

---

## ğŸ–¼ï¸ 2. ä»£æ›¿ç”»åƒç”Ÿæˆã‚µãƒ¼ãƒ“ã‚¹ã®å°å…¥

### 2.1 Replicate (Nanabanana / Flux)

**ç‰¹å¾´**:
- ã‚ˆã‚Šè‡ªç„¶ãªç”»åƒç”Ÿæˆ
- ã‚¢ãƒ‹ãƒ¡ã‚¹ã‚¿ã‚¤ãƒ«ã«å¼·ã„
- ã‚³ã‚¹ãƒˆåŠ¹ç‡ãŒè‰¯ã„ï¼ˆ$0.003ï½0.01/ç”»åƒï¼‰
- APIãŒä½¿ã„ã‚„ã™ã„

**å®Ÿè£…ä¾‹**:
```python
import replicate

def generate_image_with_flux(prompt, aspect_ratio="9:16"):
    """
    Flux ãƒ¢ãƒ‡ãƒ«ã§ç”»åƒç”Ÿæˆ
    """
    output = replicate.run(
        "black-forest-labs/flux-1.1-pro",
        input={
            "prompt": prompt,
            "aspect_ratio": aspect_ratio,
            "output_format": "png",
            "output_quality": 100
        }
    )
    return output
```

**å‚è€ƒãƒªãƒ³ã‚¯**:
- https://replicate.com/black-forest-labs/flux-1.1-pro
- https://replicate.com/pricing

### 2.2 Stability AI (Stable Diffusion XL)

**ç‰¹å¾´**:
- ã‚ªãƒ¼ãƒ—ãƒ³ã‚½ãƒ¼ã‚¹
- ã‚«ã‚¹ã‚¿ãƒã‚¤ã‚ºæ€§ãŒé«˜ã„
- ãƒã‚¬ãƒ†ã‚£ãƒ–ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆå¯¾å¿œ

**å®Ÿè£…ä¾‹**:
```python
from stability_sdk import client
import stability_sdk.interfaces.gooseai.generation.generation_pb2 as generation

stability_api = client.StabilityInference(
    key=os.environ['STABILITY_KEY'],
    engine="stable-diffusion-xl-1024-v1-0"
)

answers = stability_api.generate(
    prompt=prompt,
    negative_prompt="ugly, blurry, low quality",
    steps=50,
    cfg_scale=8.0,
    width=1024,
    height=1024
)
```

### 2.3 Midjourney (å°†æ¥çš„)

ç¾åœ¨ã¯DiscordçµŒç”±ã®ã¿ã ãŒã€å…¬å¼APIå¾…ã¡ã€‚
ç”»åƒå“è³ªã¯æœ€é«˜ã‚¯ãƒ©ã‚¹ã€‚

---

## ğŸ¤ 3. éŸ³å£°å“è³ªã®å‘ä¸Š

### å•é¡Œç‚¹
- OpenAI TTSã¯é«˜å“è³ªã ãŒã€ã‚ˆã‚Šè‡ªç„¶ãªæ—¥æœ¬èªãŒæ¬²ã—ã„å ´åˆãŒã‚ã‚‹
- å£°ã®ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ãŒé™å®šçš„

### æ”¹å–„æ¡ˆ

#### 3.1 Google Cloud Text-to-Speech

**ç‰¹å¾´**:
- WaveNet/Neural2ã‚¨ãƒ³ã‚¸ãƒ³
- ã‚ˆã‚Šè‡ªç„¶ãªæ—¥æœ¬èªã‚¤ãƒ³ãƒˆãƒãƒ¼ã‚·ãƒ§ãƒ³
- è±Šå¯Œãªæ—¥æœ¬èªéŸ³å£°ï¼ˆ30ç¨®é¡ä»¥ä¸Šï¼‰
- æ„Ÿæƒ…è¡¨ç¾ãŒå¯èƒ½ï¼ˆSSMLå¯¾å¿œï¼‰

**å®Ÿè£…ä¾‹**:
```python
from google.cloud import texttospeech

def synthesize_with_google(text, voice_name="ja-JP-Neural2-B"):
    """
    Google Cloud TTSã§éŸ³å£°åˆæˆ
    """
    client = texttospeech.TextToSpeechClient()

    synthesis_input = texttospeech.SynthesisInput(text=text)

    voice = texttospeech.VoiceSelectionParams(
        language_code="ja-JP",
        name=voice_name,
        ssml_gender=texttospeech.SsmlVoiceGender.NEUTRAL
    )

    audio_config = texttospeech.AudioConfig(
        audio_encoding=texttospeech.AudioEncoding.MP3,
        speaking_rate=1.2,  # é€Ÿåº¦èª¿æ•´
        pitch=0.0,  # ãƒ”ãƒƒãƒèª¿æ•´
        effects_profile_id=["small-bluetooth-speaker-class-device"]
    )

    response = client.synthesize_speech(
        input=synthesis_input, voice=voice, audio_config=audio_config
    )

    return response.audio_content
```

**æ–™é‡‘**:
- WaveNet: $16.00 / 1Mæ–‡å­—
- Neural2: $16.00 / 1Mæ–‡å­—
- Standard: $4.00 / 1Mæ–‡å­—

**å‚è€ƒãƒªãƒ³ã‚¯**:
- https://cloud.google.com/text-to-speech

#### 3.2 ElevenLabs

**ç‰¹å¾´**:
- è¶…é«˜å“è³ªï¼ˆäººé–“ã¨åŒºåˆ¥ãŒã¤ã‹ãªã„ãƒ¬ãƒ™ãƒ«ï¼‰
- æ„Ÿæƒ…è¡¨ç¾ãŒè±Šã‹
- å£°ã®ã‚¯ãƒ­ãƒ¼ãƒ‹ãƒ³ã‚°ã‚‚å¯èƒ½

**ãƒ‡ãƒ¡ãƒªãƒƒãƒˆ**:
- ã‚³ã‚¹ãƒˆãŒé«˜ã„ï¼ˆ$0.30/1000æ–‡å­—ç¨‹åº¦ï¼‰
- ä¸»ã«è‹±èªã«ç‰¹åŒ–

#### 3.3 VOICEVOX

**ç‰¹å¾´**:
- å®Œå…¨ç„¡æ–™
- æ—¥æœ¬èªç‰¹åŒ–
- ãƒ­ãƒ¼ã‚«ãƒ«ã§å®Ÿè¡Œå¯èƒ½
- ã‚¢ãƒ‹ãƒ¡ãƒ»ã‚­ãƒ£ãƒ©ã‚¯ã‚¿ãƒ¼é¢¨ã®å£°

**å®Ÿè£…ä¾‹**:
```python
import requests

def synthesize_with_voicevox(text, speaker=1):
    """
    VOICEVOXã§éŸ³å£°åˆæˆï¼ˆãƒ­ãƒ¼ã‚«ãƒ«ã‚µãƒ¼ãƒãƒ¼å¿…é ˆï¼‰
    """
    # éŸ³å£°ã‚¯ã‚¨ãƒªã‚’ä½œæˆ
    query_response = requests.post(
        "http://localhost:50021/audio_query",
        params={"text": text, "speaker": speaker}
    )
    query = query_response.json()

    # éŸ³å£°åˆæˆ
    synthesis_response = requests.post(
        "http://localhost:50021/synthesis",
        params={"speaker": speaker},
        json=query
    )

    return synthesis_response.content
```

**å‚è€ƒãƒªãƒ³ã‚¯**:
- https://voicevox.hiroshiba.jp/

---

## ğŸ¬ 4. å‹•ç”»å“è³ªã®å‘ä¸Š

### 4.1 ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½

**ç¾åœ¨ã®å•é¡Œ**:
- å‹•ç”»ç”Ÿæˆã«æ•°åˆ†ã‹ã‹ã‚‹ãŸã‚ã€è©¦è¡ŒéŒ¯èª¤ãŒé›£ã—ã„

**æ”¹å–„æ¡ˆ**:
```python
def generate_preview_video(scenes, duration_limit=10):
    """
    æœ€åˆã®10ç§’ã ã‘ã®ä½è§£åƒåº¦ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚’ç”Ÿæˆ
    """
    preview_scenes = []
    total_duration = 0

    for scene in scenes:
        if total_duration + scene['duration'] > duration_limit:
            break
        preview_scenes.append(scene)
        total_duration += scene['duration']

    # ä½è§£åƒåº¦ã§é«˜é€Ÿç”Ÿæˆ
    return render_video(
        preview_scenes,
        resolution=(640, 360),  # ä½è§£åƒåº¦
        fps=15,  # ä½ãƒ•ãƒ¬ãƒ¼ãƒ ãƒ¬ãƒ¼ãƒˆ
        preset='ultrafast'  # é«˜é€Ÿã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
    )
```

### 4.2 è§£åƒåº¦ã‚ªãƒ—ã‚·ãƒ§ãƒ³

```python
RESOLUTION_PRESETS = {
    "4K": (3840, 2160),
    "1080p": (1920, 1080),
    "720p": (1280, 720),
    "480p": (854, 480)
}
```

### 4.3 SNSæœ€é©åŒ–ãƒ—ãƒªã‚»ãƒƒãƒˆ

```python
SNS_PRESETS = {
    "TikTok": {
        "aspect_ratio": "9:16",
        "resolution": (1080, 1920),
        "max_duration": 60,
        "fps": 30
    },
    "Instagram Reels": {
        "aspect_ratio": "9:16",
        "resolution": (1080, 1920),
        "max_duration": 90,
        "fps": 30
    },
    "YouTube Shorts": {
        "aspect_ratio": "9:16",
        "resolution": (1080, 1920),
        "max_duration": 60,
        "fps": 24
    },
    "Twitter": {
        "aspect_ratio": "16:9",
        "resolution": (1280, 720),
        "max_duration": 140,
        "fps": 30
    }
}
```

---

## ğŸŒ 5. å¤šè¨€èªå¯¾å¿œ

### 5.1 å¯¾è±¡è¨€èª
- è‹±èªï¼ˆã‚°ãƒ­ãƒ¼ãƒãƒ«å±•é–‹ï¼‰
- ä¸­å›½èªï¼ˆç°¡ä½“å­—ãƒ»ç¹ä½“å­—ï¼‰
- éŸ“å›½èª
- ã‚¹ãƒšã‚¤ãƒ³èª

### 5.2 å®Ÿè£…æ–¹æ³•

```python
# backend/translator.py
from google.cloud import translate_v2 as translate

def translate_scenario(text, target_language="en"):
    """
    ã‚·ãƒŠãƒªã‚ªã‚’ç¿»è¨³
    """
    translate_client = translate.Client()
    result = translate_client.translate(
        text,
        target_language=target_language
    )
    return result['translatedText']

# ç”»åƒãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚‚ç¿»è¨³
def translate_image_prompt(prompt, target_language="en"):
    # è‹±èªãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¯ãã®ã¾ã¾ä½¿ç”¨
    if target_language == "en":
        return prompt
    # ãã®ä»–ã¯è‹±èªã«ç¿»è¨³
    return translate_scenario(prompt, "en")
```

---

## ğŸµ 6. BGMæ©Ÿèƒ½ã®æ‹¡å¼µ

### 6.1 ã‚«ã‚¹ã‚¿ãƒ BGMã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰

```python
# pages/5_audio_settings.py
uploaded_bgm = st.file_uploader(
    "ã‚«ã‚¹ã‚¿ãƒ BGMã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰",
    type=["mp3", "wav", "m4a"],
    help="å‹•ç”»ã§ä½¿ç”¨ã—ãŸã„BGMãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰"
)

if uploaded_bgm:
    # ä¸€æ™‚ä¿å­˜
    bgm_path = save_uploaded_file(uploaded_bgm)
    st.session_state.selected_bgm = bgm_path
```

### 6.2 BGMè‡ªå‹•é¸æŠ

```python
def auto_select_bgm(scenario_tone, scenario_content):
    """
    ã‚·ãƒŠãƒªã‚ªã®å†…å®¹ã«åŸºã¥ã„ã¦BGMã‚’è‡ªå‹•é¸æŠ
    """
    # Gemini APIã§åˆ†æ
    analysis = analyze_scenario_mood(scenario_content)

    bgm_mapping = {
        "energetic": "natsuyasuminotanken.mp3",
        "modern": "neonpurple.mp3",
        "calm": "yoiyaminoseaside.mp3",
        "dreamy": "yume.mp3"
    }

    return bgm_mapping.get(analysis['mood'], "yume.mp3")
```

### 6.3 BGMã®ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³/ã‚¢ã‚¦ãƒˆ

```python
def add_bgm_with_fade(video, bgm, fade_duration=2.0):
    """
    BGMã«ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³/ã‚¢ã‚¦ãƒˆã‚’è¿½åŠ 
    """
    bgm_clip = AudioFileClip(bgm)

    # ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¤ãƒ³
    bgm_clip = bgm_clip.audio_fadein(fade_duration)

    # ãƒ•ã‚§ãƒ¼ãƒ‰ã‚¢ã‚¦ãƒˆ
    bgm_clip = bgm_clip.audio_fadeout(fade_duration)

    return video.set_audio(
        CompositeAudioClip([video.audio, bgm_clip])
    )
```

---

## ğŸ”§ 7. ã‚·ã‚¹ãƒ†ãƒ æ”¹å–„

### 7.1 ãƒãƒƒãƒå‡¦ç†

è¤‡æ•°ã®EPUBã‚’ä¸€åº¦ã«å‡¦ç†ï¼š

```python
def batch_process_epubs(epub_files, settings):
    """
    è¤‡æ•°ã®EPUBãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¸€æ‹¬å‡¦ç†
    """
    results = []

    for epub_file in epub_files:
        try:
            video = generate_video_pipeline(epub_file, settings)
            results.append({
                "file": epub_file,
                "status": "success",
                "video": video
            })
        except Exception as e:
            results.append({
                "file": epub_file,
                "status": "error",
                "error": str(e)
            })

    return results
```

### 7.2 é€²è¡ŒçŠ¶æ³ã®æ°¸ç¶šåŒ–

```python
# backend/progress_manager.py
def save_progress(project_id, step, data):
    """
    é€²è¡ŒçŠ¶æ³ã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
    """
    progress = {
        "project_id": project_id,
        "step": step,
        "data": data,
        "timestamp": datetime.now()
    }

    # SQLiteã‚„Firebaseã«ä¿å­˜
    db.save(progress)

def resume_from_progress(project_id):
    """
    ä¿å­˜ã•ã‚ŒãŸé€²è¡ŒçŠ¶æ³ã‹ã‚‰å†é–‹
    """
    progress = db.load(project_id)
    return progress
```

### 7.3 ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ã®å¼·åŒ–

```python
# backend/error_handler.py
def retry_with_backoff(func, max_retries=3, initial_delay=1):
    """
    æŒ‡æ•°ãƒãƒƒã‚¯ã‚ªãƒ•ã§ãƒªãƒˆãƒ©ã‚¤
    """
    for i in range(max_retries):
        try:
            return func()
        except Exception as e:
            if i == max_retries - 1:
                raise
            delay = initial_delay * (2 ** i)
            print(f"ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿã€{delay}ç§’å¾Œã«ãƒªãƒˆãƒ©ã‚¤: {e}")
            time.sleep(delay)
```

---

## ğŸ“Š 8. åˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½

### 8.1 å‹•ç”»å“è³ªã‚¹ã‚³ã‚¢

```python
def analyze_video_quality(video_path):
    """
    ç”Ÿæˆã•ã‚ŒãŸå‹•ç”»ã®å“è³ªã‚’åˆ†æ
    """
    analysis = {
        "resolution": get_resolution(video_path),
        "fps": get_fps(video_path),
        "bitrate": get_bitrate(video_path),
        "duration": get_duration(video_path),
        "audio_quality": analyze_audio(video_path),
        "scene_transitions": count_transitions(video_path)
    }

    # ã‚¹ã‚³ã‚¢è¨ˆç®—
    score = calculate_quality_score(analysis)

    return {
        "score": score,
        "details": analysis,
        "recommendations": get_recommendations(analysis)
    }
```

### 8.2 ç”Ÿæˆå±¥æ­´ã®è¨˜éŒ²

```python
# å„ç”Ÿæˆã®è¨˜éŒ²ã‚’ä¿å­˜
generation_log = {
    "timestamp": datetime.now(),
    "book_name": book_name,
    "scenario_type": scenario['pattern_name'],
    "visual_style": visual_style,
    "num_scenes": num_scenes,
    "generation_time": elapsed_time,
    "api_costs": {
        "gemini": gemini_cost,
        "dalle": dalle_cost,
        "tts": tts_cost
    },
    "video_url": video_path
}
```

---

## ğŸ¯ 9. å„ªå…ˆé †ä½

### é«˜å„ªå…ˆåº¦ï¼ˆã™ãã«å®Ÿè£…ã™ã¹ãï¼‰
1. âœ… **ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢ãƒªãƒ³ã‚°å¼·åŒ–** - ã‚³ã‚¹ãƒˆã‚¼ãƒ­ã§å“è³ªå‘ä¸Š
2. â­ **Google Cloud TTSå°å…¥** - ã‚ˆã‚Šè‡ªç„¶ãªæ—¥æœ¬èª
3. â­ **ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½** - UXå‘ä¸Š

### ä¸­å„ªå…ˆåº¦ï¼ˆæ¤œè¨ä¾¡å€¤ã‚ã‚Šï¼‰
4. ğŸ”µ **Replicate (Flux) å°å…¥** - ã‚³ã‚¹ãƒˆå‰Šæ¸›ï¼‹å“è³ªå‘ä¸Š
5. ğŸ”µ **ã‚«ã‚¹ã‚¿ãƒ BGMã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰** - ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æœ›ã«å¿œãˆã‚‹
6. ğŸ”µ **SNSæœ€é©åŒ–ãƒ—ãƒªã‚»ãƒƒãƒˆ** - å®Ÿç”¨æ€§å‘ä¸Š

### ä½å„ªå…ˆåº¦ï¼ˆå°†æ¥çš„ã«ï¼‰
7. ğŸŸ¡ å¤šè¨€èªå¯¾å¿œ
8. ğŸŸ¡ ãƒãƒƒãƒå‡¦ç†
9. ğŸŸ¡ åˆ†æãƒ»ãƒ¬ãƒãƒ¼ãƒˆæ©Ÿèƒ½

---

## ğŸ’° ã‚³ã‚¹ãƒˆè©¦ç®—

### ç¾åœ¨ã®æ§‹æˆï¼ˆ1å‹•ç”»ã‚ãŸã‚Šï¼‰
- DALL-E 3 standard (5ã‚·ãƒ¼ãƒ³): $0.20
- OpenAI TTS (500æ–‡å­—Ã—5): $0.075
- Gemini Flash (3å›): $0.00001
- **åˆè¨ˆ**: ç´„ $0.28 / å‹•ç”»

### æ”¹å–„å¾Œã®æ§‹æˆä¾‹
- Flux (5ã‚·ãƒ¼ãƒ³): $0.05
- Google Cloud TTS Neural2 (500æ–‡å­—Ã—5): $0.04
- Gemini Flash (3å›): $0.00001
- **åˆè¨ˆ**: ç´„ $0.09 / å‹•ç”»

**ã‚³ã‚¹ãƒˆå‰Šæ¸›**: ç´„70%å‰Šæ¸›å¯èƒ½

---

## ğŸ“š å‚è€ƒãƒªãƒ³ã‚¯

### ç”»åƒç”Ÿæˆ
- [DALL-E 3 Documentation](https://platform.openai.com/docs/guides/images)
- [Replicate Flux Models](https://replicate.com/collections/flux)
- [Stability AI](https://platform.stability.ai/)

### éŸ³å£°åˆæˆ
- [Google Cloud TTS](https://cloud.google.com/text-to-speech)
- [ElevenLabs](https://elevenlabs.io/)
- [VOICEVOX](https://voicevox.hiroshiba.jp/)

### å‹•ç”»å‡¦ç†
- [MoviePy Documentation](https://zulko.github.io/moviepy/)
- [FFmpeg Documentation](https://ffmpeg.org/documentation.html)

---

## ğŸ“ å®Ÿè£…æ™‚ã®æ³¨æ„ç‚¹

1. **APIåˆ¶é™**
   - å„ã‚µãƒ¼ãƒ“ã‚¹ã®ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã«æ³¨æ„
   - ãƒªãƒˆãƒ©ã‚¤ãƒ­ã‚¸ãƒƒã‚¯ã‚’å®Ÿè£…

2. **ã‚³ã‚¹ãƒˆç®¡ç†**
   - ä½¿ç”¨é‡ã®ç›£è¦–
   - æœˆé–“äºˆç®—ã®è¨­å®š

3. **ã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°**
   - ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå‡¦ç†
   - éƒ¨åˆ†çš„ãªå¤±æ•—ã‹ã‚‰ã®å¾©æ—§

4. **ãƒ†ã‚¹ãƒˆ**
   - å„æ”¹å–„ã«ã¤ã„ã¦ååˆ†ãªãƒ†ã‚¹ãƒˆ
   - ï¿½ï¿½ï¿½ãƒ¼ã‚¶ãƒ¼ãƒ•ã‚£ãƒ¼ãƒ‰ãƒãƒƒã‚¯ã®åé›†

---

**æœ€çµ‚æ›´æ–°**: 2025-10-27
**ãƒãƒ¼ã‚¸ãƒ§ãƒ³**: v2.0
