#!/usr/bin/env python3
"""
æ›¸ç±æ¦‚è¦ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«

EPUBã‹ã‚‰æŠ½å‡ºã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‹ã‚‰ã€è«–æ–‡å½¢å¼ã®å®¢è¦³çš„ãªæ¦‚è¦ã‚’ç”Ÿæˆ
"""

from pathlib import Path
from typing import Dict, Any
import google.generativeai as genai
import os
import json
from dotenv import load_dotenv

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()


def chunk_text(text: str, chunk_size: int = 2000) -> list[str]:
    """
    ãƒ†ã‚­ã‚¹ãƒˆã‚’æŒ‡å®šã‚µã‚¤ã‚ºã®ãƒãƒ£ãƒ³ã‚¯ã«åˆ†å‰²

    Args:
        text: åˆ†å‰²ã™ã‚‹ãƒ†ã‚­ã‚¹ãƒˆ
        chunk_size: ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆæ–‡å­—æ•°ï¼‰

    Returns:
        ãƒãƒ£ãƒ³ã‚¯ã®ãƒªã‚¹ãƒˆ
    """
    chunks = []
    current_chunk = ""

    # æ®µè½ã”ã¨ã«å‡¦ç†
    paragraphs = text.split('\n\n')

    for para in paragraphs:
        if len(current_chunk) + len(para) <= chunk_size:
            current_chunk += para + "\n\n"
        else:
            if current_chunk:
                chunks.append(current_chunk.strip())
            current_chunk = para + "\n\n"

    # æœ€å¾Œã®ãƒãƒ£ãƒ³ã‚¯ã‚’è¿½åŠ 
    if current_chunk:
        chunks.append(current_chunk.strip())

    return chunks


def summarize_chunk(chunk: str, chunk_index: int, model) -> str:
    """
    å˜ä¸€ãƒãƒ£ãƒ³ã‚¯ã®è¦ç´„ã‚’ç”Ÿæˆ

    Args:
        chunk: ãƒãƒ£ãƒ³ã‚¯ãƒ†ã‚­ã‚¹ãƒˆ
        chunk_index: ãƒãƒ£ãƒ³ã‚¯ç•ªå·
        model: Gemini model

    Returns:
        è¦ç´„ãƒ†ã‚­ã‚¹ãƒˆ
    """
    prompt = f"""
ä»¥ä¸‹ã®ãƒ†ã‚­ã‚¹ãƒˆï¼ˆãƒãƒ£ãƒ³ã‚¯{chunk_index + 1}ï¼‰ã‚’200-300æ–‡å­—ã§è¦ç´„ã—ã¦ãã ã•ã„ã€‚

## ãƒ†ã‚­ã‚¹ãƒˆ
{chunk}

---

**è¦ä»¶:**
- å®¢è¦³çš„ãƒ»ä¸­ç«‹çš„ã«
- ä¸»è¦ãªå†…å®¹ã‚’ç°¡æ½”ã«
- äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã§

200-300æ–‡å­—ã®è¦ç´„ã®ã¿ã‚’å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
"""

    response = model.generate_content(
        prompt,
        generation_config={"temperature": 0.3}
    )

    return response.text.strip()


def generate_book_summary(book_name: str, full_text: str, target_length: int = 800) -> Dict[str, Any]:
    """
    æ›¸ç±ã®å®¢è¦³çš„ãªæ¦‚è¦ã‚’ç”Ÿæˆï¼ˆè«–æ–‡å½¢å¼ï¼‰

    Args:
        book_name: æ›¸ç±å
        full_text: æ›¸ç±ã®å…¨æ–‡ãƒ†ã‚­ã‚¹ãƒˆ
        target_length: ç›®æ¨™æ–‡å­—æ•°ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ800æ–‡å­—ï¼‰

    Returns:
        æ¦‚è¦æƒ…å ±ã‚’å«ã‚€è¾æ›¸
    """

    # Gemini APIè¨­å®š
    api_key = os.getenv("GOOGLE_API_KEY")
    if not api_key:
        raise ValueError("GOOGLE_API_KEYç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")

    genai.configure(api_key=api_key)
    model = genai.GenerativeModel('gemini-2.5-flash-lite')

    # ãƒ†ã‚­ã‚¹ãƒˆãŒé•·ã™ãã‚‹å ´åˆã¯æœ€åˆã®éƒ¨åˆ†ã®ã¿ä½¿ç”¨ï¼ˆãƒˆãƒ¼ã‚¯ãƒ³åˆ¶é™å¯¾ç­–ï¼‰
    max_chars = 50000
    text_for_analysis = full_text[:max_chars] if len(full_text) > max_chars else full_text

    prompt = f"""
ã‚ãªãŸã¯å­¦è¡“è«–æ–‡ã®è¦æ—¨ã‚’æ›¸ãå°‚é–€å®¶ã§ã™ã€‚
ä»¥ä¸‹ã®æ›¸ç±ãƒ†ã‚­ã‚¹ãƒˆã‚’èª­ã¿ã€**è«–æ–‡ã®è¦æ—¨ï¼ˆã‚¢ãƒ–ã‚¹ãƒˆãƒ©ã‚¯ãƒˆï¼‰å½¢å¼**ã§å®¢è¦³çš„ãªæ¦‚è¦ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

## æ›¸ç±å
{book_name}

## æ›¸ç±ãƒ†ã‚­ã‚¹ãƒˆï¼ˆæŠœç²‹ï¼‰
{text_for_analysis}

---

## ã‚¿ã‚¹ã‚¯

ã“ã®æ›¸ç±ã«ã¤ã„ã¦ã€**{target_length}æ–‡å­—ç¨‹åº¦**ã®å®¢è¦³çš„ãªæ¦‚è¦ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

### è¦ä»¶

1. **è«–æ–‡ã®è¦æ—¨å½¢å¼**
   - å®¢è¦³çš„ãƒ»ä¸­ç«‹çš„ãªè¨˜è¿°
   - äº‹å®Ÿãƒ™ãƒ¼ã‚¹ã®èª¬æ˜
   - å®£ä¼çš„ãªè¡¨ç¾ã¯ä¸€åˆ‡ä½¿ã‚ãªã„
   - æ„Ÿæƒ…çš„ãªè¡¨ç¾ã¯é¿ã‘ã‚‹

2. **å«ã‚ã‚‹ã¹ãå†…å®¹**
   - æ›¸ç±ã®ä¸»é¡Œãƒ»ãƒ†ãƒ¼ãƒ
   - æ‰±ã£ã¦ã„ã‚‹å†…å®¹ã®æ¦‚è¦
   - ä¸»è¦ãªè«–ç‚¹ã‚„ãƒˆãƒ”ãƒƒã‚¯
   - æ›¸ç±ã®æ§‹æˆï¼ˆç« ç«‹ã¦ç­‰ãŒã‚ã‚Œã°ï¼‰
   - å¯¾è±¡èª­è€…å±¤ï¼ˆå®¢è¦³çš„ã«ï¼‰
   - æ›¸ç±ã®ç‰¹å¾´ã‚„ç‹¬è‡ªæ€§ï¼ˆã‚ã‚‹å ´åˆï¼‰

3. **æ–‡ä½“**
   - ã€Œã§ã‚ã‚‹ã€èª¿ã®è«–æ–‡å½¢å¼
   - ç°¡æ½”ã§æ˜ç­ãªæ–‡ç« 
   - å°‚é–€ç”¨èªã¯é©å®œä½¿ç”¨
   - æ®µè½åˆ†ã‘ã¯é©åˆ‡ã«

4. **é¿ã‘ã‚‹ã¹ãè¡¨ç¾**
   - ã€Œé¢ç™½ã„ã€ã€Œæ„Ÿå‹•çš„ã€ãªã©ã®ä¸»è¦³çš„è©•ä¾¡
   - ã€Œå¿…èª­ã€ã€ŒãŠã™ã™ã‚ã€ãªã©ã®å®£ä¼æ–‡å¥
   - ã€Œãœã²ã€ã€Œãã£ã¨ã€ãªã©ã®å‹§èª˜è¡¨ç¾
   - èª­è€…ã¸ã®ç›´æ¥çš„ãªå‘¼ã³ã‹ã‘

5. **æ–‡å­—æ•°**
   - {target_length - 100}ï½{target_length + 200}æ–‡å­—
   - é©åˆ‡ãªæ®µè½åˆ†ã‘ã§èª­ã¿ã‚„ã™ã

---

JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚

å‡ºåŠ›å½¢å¼:
{{
  "summary": "è«–æ–‡å½¢å¼ã®æ¦‚è¦æœ¬æ–‡ï¼ˆ{target_length}æ–‡å­—ç¨‹åº¦ï¼‰",
  "character_count": å®Ÿéš›ã®æ–‡å­—æ•°,
  "main_topics": ["ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯1", "ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯2", "ä¸»è¦ãƒˆãƒ”ãƒƒã‚¯3"],
  "target_audience": "æƒ³å®šã•ã‚Œã‚‹èª­è€…å±¤ï¼ˆå®¢è¦³çš„è¡¨ç¾ï¼‰",
  "book_type": "æ›¸ç±ã®ç¨®é¡ï¼ˆå°èª¬ã€å®Ÿç”¨æ›¸ã€å­¦è¡“æ›¸ç­‰ï¼‰"
}}
"""

    print(f"  ğŸ¤– Gemini APIã§æ›¸ç±æ¦‚è¦ã‚’ç”Ÿæˆä¸­ï¼ˆç›®æ¨™{target_length}æ–‡å­—ï¼‰...")
    response = model.generate_content(
        prompt,
        generation_config={
            "temperature": 0.3,  # å®¢è¦³æ€§ã‚’ä¿ã¤ãŸã‚ä½ã‚ã«è¨­å®š
            "response_mime_type": "application/json"
        }
    )

    result = json.loads(response.text)

    print(f"  âœ“ æ›¸ç±æ¦‚è¦ç”Ÿæˆå®Œäº†ï¼ˆ{result['character_count']}æ–‡å­—ï¼‰")

    return result


def save_summary(summary: Dict[str, Any], book_name: str) -> Path:
    """
    ç”Ÿæˆã—ãŸæ¦‚è¦ã‚’ä¿å­˜

    Args:
        summary: æ¦‚è¦ãƒ‡ãƒ¼ã‚¿
        book_name: æ›¸ç±å

    Returns:
        ä¿å­˜å…ˆãƒ‘ã‚¹
    """
    from .utils import get_project_root, save_json

    project_root = get_project_root()
    internal_dir = project_root / "data" / "internal"
    internal_dir.mkdir(parents=True, exist_ok=True)

    summary_file = internal_dir / "book_summary.json"

    summary_data = {
        "book_name": book_name,
        **summary
    }

    save_json(summary_file, summary_data)
    print(f"  ğŸ’¾ æ¦‚è¦ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜: {summary_file}")

    return summary_file
